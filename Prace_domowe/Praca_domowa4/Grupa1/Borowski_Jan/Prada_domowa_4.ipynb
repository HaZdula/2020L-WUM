{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import category_encoders as ce\n",
    "import matplotlib as plt\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiór apartments\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('apartments.cvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      "Unnamed: 0           1000 non-null int64\n",
      "m2.price             1000 non-null int64\n",
      "construction.year    1000 non-null int64\n",
      "surface              1000 non-null int64\n",
      "floor                1000 non-null int64\n",
      "no.rooms             1000 non-null int64\n",
      "district             1000 non-null object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jako zmienną celu potraktuję zmienną m2.price toworząc w ten sposób zadanie Regresi\n",
    "\n",
    "# kolumna pierwsza to indeksy można usunąć \n",
    "data = data.drop('Unnamed: 0',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podziła na zbiór testowy/ternignowy \n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('m2.price', axis=1), data['m2.price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m2.price</th>\n",
       "      <th>construction.year</th>\n",
       "      <th>surface</th>\n",
       "      <th>floor</th>\n",
       "      <th>no.rooms</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5897</td>\n",
       "      <td>1953</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Srodmiescie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1818</td>\n",
       "      <td>1992</td>\n",
       "      <td>143</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Bielany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3643</td>\n",
       "      <td>1937</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Praga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3517</td>\n",
       "      <td>1995</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Ochota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3013</td>\n",
       "      <td>1992</td>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Mokotow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m2.price  construction.year  surface  floor  no.rooms     district\n",
       "0      5897               1953       25      3         1  Srodmiescie\n",
       "1      1818               1992      143      9         5      Bielany\n",
       "2      3643               1937       56      1         2        Praga\n",
       "3      3517               1995       93      7         3       Ochota\n",
       "4      3013               1992      144      6         5      Mokotow"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Użyję One-hote encodingu \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 882.0373554174482\n",
      "R2 score : -0.004578174264286972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SVM bez skalowania \n",
    "\n",
    "\n",
    "svm_ = SVR()\n",
    "ohe = ce.OneHotEncoder()\n",
    "\n",
    "# OHE\n",
    "svm_.fit(ohe.fit_transform(X_train),y_train)\n",
    "y_pred_ohe = svm_.predict(ohe.transform(X_test))\n",
    "\n",
    "\n",
    "\n",
    "print(f'RMSE : {mean_squared_error(y_test,y_pred_ohe,squared=False)}')\n",
    "print(f'R2 score : {r2_score(y_test,y_pred_ohe)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bez skalowania wynik tregiczne gorsze niż podawanie stałej wartosci dla każdego przypadku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 578 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1178 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1978 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2978 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3552 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4178 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4852 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4985 out of 5000 | elapsed:  1.8min remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                                 epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                                 max_iter=-1, shrinking=True, tol=0.001,\n",
       "                                 verbose=False),\n",
       "                   iid='deprecated', n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f0725181e10>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f0723641fd0>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strojenie parametrów bez skalowanie \n",
    "from scipy.stats import uniform\n",
    "\n",
    "param_distribution = {\n",
    "    'gamma': uniform(),\n",
    "    'C':uniform(0,10000),\n",
    "    \n",
    "    \n",
    "}\n",
    "rps_no = RandomizedSearchCV(SVR(epsilon=0.1),param_distributions=param_distribution,cv=5,n_iter=1000,verbose=6,n_jobs=-1)\n",
    "rps_no.fit(ohe.fit_transform(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5375722544386464"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_no = rps_no.best_estimator_\n",
    "rps_no.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_scaled : 860.4664138232931\n",
      "R2 score_scaled : 0.04395655490587591\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "scal = StandardScaler(copy=False)\n",
    "\n",
    "svm_ = SVR()\n",
    "ohe = ce.OneHotEncoder()\n",
    "\n",
    "columns_to_sclae =X_train.columns[:-1]\n",
    "\n",
    "scaled_X_train = X_train.copy()\n",
    "scaled_X_test = X_test.copy()\n",
    "\n",
    "scaled_X_train[columns_to_sclae] = scal.fit_transform(scaled_X_train[columns_to_sclae])\n",
    "scaled_X_test[columns_to_sclae] = scal.transform(scaled_X_test[columns_to_sclae])\n",
    "\n",
    "# OHE\n",
    "svm_.fit(ohe.fit_transform(scaled_X_train),y_train)\n",
    "y_pred_ohe = svm_.predict(ohe.transform(scaled_X_test))\n",
    "\n",
    "\n",
    "\n",
    "print(f'RMSE_scaled : {mean_squared_error(y_test,y_pred_ohe,squared=False)}')\n",
    "print(f'R2 score_scaled : {r2_score(y_test,y_pred_ohe)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po przeskalowaniu wynik jest wyraznie lepszy choć nie zbyt zadowalający. Może pomoże dobranie własciwych parametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "param_distribution = {\n",
    "    'gamma': uniform(),\n",
    "    'C':uniform(0,10000),\n",
    "    \n",
    "    \n",
    "}\n",
    "rps = RandomizedSearchCV(SVR(epsilon=0.1),param_distributions=param_distribution,cv=5,n_iter=1000,verbose=6,n_jobs=-1)\n",
    "# Poniważ używam one hota nie ma potrzeby użyć piplinu z kodowaniem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1497 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2097 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2797 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3597 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4497 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9737447991417044"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rps.fit(ohe.fit_transform(scaled_X_train),y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9737447991417044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 9434.121037971136, 'gamma': 0.014886955084316145}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Best score: {rps.best_score_}')\n",
    "rps.best_params_ \n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skalowane</th>\n",
       "      <th>Nie skalowane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>154.652057</td>\n",
       "      <td>549.792143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.969117</td>\n",
       "      <td>0.609693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Skalowane  Nie skalowane\n",
       "RMSE  154.652057     549.792143\n",
       "R2      0.969117       0.609693"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porówanie wyników dla skalowania i bez skalowania \n",
    "ohe =ce.OneHotEncoder()\n",
    "svm_best=rps.best_estimator_\n",
    "svm_best.fit(ohe.fit_transform(scaled_X_train),y_train)\n",
    "y_pred_ohe_s = svm_best.predict(ohe.transform(scaled_X_test))\n",
    "ohe =ce.OneHotEncoder()\n",
    "best_no.fit(ohe.fit_transform(X_train),y_train)\n",
    "y_ped_ohe_no = best_no.predict(ohe.transform(X_test))\n",
    "\n",
    "\n",
    "\n",
    "dane = {'Skalowane' : [mean_squared_error(y_test,y_pred_ohe,squared=False),r2_score(y_test,y_pred_ohe)],\n",
    "        'Nie skalowane': [mean_squared_error(y_test,y_ped_ohe_no,squared=False),r2_score(y_test,y_ped_ohe_no)]}\n",
    "pd.DataFrame(data=dane,columns=['Skalowane','Nie skalowane'],index=['RMSE','R2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyraznie widać róznicę wynikającą tylko ze sklaowania danych (ewentualnie pechowe działanie RandomSearch ale nie powinien to być problem dla 1000 iteracij) zgodnie z artykułem skalowanie danych znacząco poprawia działanie SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugi zbiór \n",
    "====\n",
    "Z biblioteki OpenMl https://www.openml.org/d/1462. Zadanie polega na klasyfikacij binarnej. Klasyfikujemy czy dana soba ma cukrzycę czy nie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "preg     768 non-null int64\n",
      "plas     768 non-null int64\n",
      "pres     768 non-null int64\n",
      "skin     768 non-null int64\n",
      "insu     768 non-null int64\n",
      "mass     768 non-null float64\n",
      "pedi     768 non-null float64\n",
      "age      768 non-null int64\n",
      "class    768 non-null object\n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 54.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv('dataset_37_diabetes.csv')\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "preg    0.901674\n",
       "plas    0.173754\n",
       "pres   -1.843608\n",
       "skin    0.109372\n",
       "insu    2.272251\n",
       "mass   -0.428982\n",
       "pedi    1.919911\n",
       "age     1.129597\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Żadna z danych nie jest bardzo skośna (nie potrzeba dodatkowych przekształceń)\n",
    "from collections import Counter\n",
    "\n",
    "print(Counter(data2['class']))\n",
    "# Klasy nie są idelanie zbalansowane ale miary takie jak acc powinny mieć sens \n",
    "data2.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trzeba poprawić labele \n",
    "data2['class'] = np.where(data2['class']=='tested_negative',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(data2.drop('class', axis=1), data2['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skalowanie \n",
    "scal = StandardScaler(copy=False)\n",
    "\n",
    "X_train2 = pd.DataFrame(scal.fit_transform(X_train2))\n",
    "X_test2 = pd.DataFrame(scal.transform(X_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.78125\n",
      "F1_score : 0.6557377049180328\n",
      "Reccal : 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "# test bez CV i z podstawowymi parametrami \n",
    "svm_ = SVC(probability=True)\n",
    "# Tym razem nie ma potrzeby kodowania \n",
    "svm_.fit(X_train2,y_train2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,auc,roc_curve,f1_score,recall_score\n",
    "\n",
    "\n",
    "y_pred = svm_.predict(X_test2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy : {accuracy_score(y_test2,y_pred)}')\n",
    "print(f'F1_score : {f1_score(y_test2,y_pred)}')\n",
    "print(f'Reccal : {recall_score(y_test2,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki zwłaszcza reccal nie są zbyt dobre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribution = {\n",
    "    \n",
    "    'gamma': uniform(),\n",
    "    \n",
    "    'C':uniform(0,10000),\n",
    "    \n",
    "}\n",
    "rps_c = RandomizedSearchCV(SVC(),param_distributions=param_distribution,cv=5,n_jobs=-1,n_iter=1000,verbose=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1108 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1656 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2308 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3056 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3908 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4856 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:   47.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                 class_weight=None, coef0=0.0,\n",
       "                                 decision_function_shape='ovr', degree=3,\n",
       "                                 gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                                 probability=False, random_state=None,\n",
       "                                 shrinking=True, tol=0.001, verbose=False),\n",
       "                   iid='deprecated', n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f073f575550>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f073f7b6790>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rps_c.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656071964017991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 2.6180354960303465, 'gamma': 0.1912181329001693}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rps_c.best_score_)\n",
    "# Najlepszy wynik nie różni się znacznie od parametrów domyślnych\n",
    "rps_c.best_params_\n",
    "# Może to oznaczać zły kernel albo duży błąd treningowy sprawdżmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train : 0.8038194444444444\n"
     ]
    }
   ],
   "source": [
    "svm_c_best = rps_c.best_estimator_\n",
    "\n",
    "svm_c_best.fit(X_train2,y_train2)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = svm_c_best.predict(X_train2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy train : {accuracy_score(y_train2,y_pred)}')\n",
    "# Zgodnie z przewidywaniami algorytm po prostu nie dopasowuję wystarczająco się do danych sprawdzę jescze inne jądra \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy linear : 0.7760416666666666\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   23.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                 class_weight=None, coef0=0.0,\n",
       "                                 decision_function_shape='ovr', degree=3,\n",
       "                                 gamma='scale', kernel='linear', max_iter=-1,\n",
       "                                 probability=False, random_state=None,\n",
       "                                 shrinking=True, tol=0.001, verbose=False),\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f0740425450>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c = SVC(kernel='linear')\n",
    "\n",
    "svm_c.fit(X_train2,y_train2)\n",
    "y_pred = svm_c.predict(X_test2)\n",
    "\n",
    "print(f'Accuracy linear : {accuracy_score(y_test2,y_pred)}')\n",
    "#Wynik podobny do jądra gausowskiego \n",
    "# Strojenie dla jądra linear \n",
    "\n",
    "param_distribution = {\n",
    "    \n",
    "    'C':uniform(0,100)    \n",
    "}\n",
    "rps_linear = RandomizedSearchCV(SVC(kernel='linear'),param_distributions=param_distribution,cv=5,n_jobs=-1,n_iter=100,verbose=6)\n",
    "rps_linear.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :0.7726086956521738\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Score :{rps_linear.best_score_}')\n",
    "# Wynik podobny jak w przypadku jądraa gausowiskiego "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy poly : 0.7239583333333334\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done 263 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 379 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                 class_weight=None, coef0=0.0,\n",
       "                                 decision_function_shape='ovr', degree=3,\n",
       "                                 gamma='scale', kernel='poly', max_iter=-1,\n",
       "                                 probability=False, random_state=None,\n",
       "                                 shrinking=True, tol=0.001, verbose=False),\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f07403fa210>,\n",
       "                                        'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                   10],\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f07403877d0>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c = SVC(kernel='poly')\n",
    "\n",
    "svm_c.fit(X_train2,y_train2)\n",
    "y_pred = svm_c.predict(X_test2)\n",
    "\n",
    "print(f'Accuracy poly : {accuracy_score(y_test2,y_pred)}')\n",
    "# Nieco niższy niż w pozostałych przypadkach \n",
    "# Strojenie dla jądra poly \n",
    "\n",
    "param_distribution = {\n",
    "    'gamma':uniform(),\n",
    "    'C':uniform(0,100),\n",
    "    'degree':[i for i in range(1,11)]\n",
    "}\n",
    "rps_poly = RandomizedSearchCV(SVC(kernel='poly'),param_distributions=param_distribution,cv=5,n_jobs=-1,n_iter=100,verbose=6)\n",
    "rps_poly.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7726086956521738"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strojenie parametrów trwało znacznie dłużej niż dla innych jąder\n",
    "rps_poly.best_score_\n",
    "# Wynik podobny jak w poprzednich przypadkach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RBF</th>\n",
       "      <th>Linear</th>\n",
       "      <th>Poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.786458</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.621849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.513889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RBF    Linear      Poly\n",
       "Accuracy  0.786458  0.770833  0.765625\n",
       "F1        0.643478  0.627119  0.621849\n",
       "Recall    0.513889  0.513889  0.513889"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_c_best = rps_c.best_estimator_\n",
    "svm_linear_best = rps_linear.best_estimator_\n",
    "svm_poly_best = rps_poly.best_estimator_\n",
    "\n",
    "svm_c_best.fit(X_train2,y_train2)\n",
    "svm_linear_best.fit(X_train2,y_train2)\n",
    "svm_poly_best.fit(X_train2,y_train2)\n",
    "\n",
    "y_pred_gaus = svm_c_best.predict(X_test2)\n",
    "y_pred_linear = svm_linear_best.predict(X_test2)\n",
    "y_pred_poly = svm_poly_best.predict(X_test2)\n",
    "\n",
    "\n",
    "data = {'RBF':[accuracy_score(y_test2,y_pred_gaus),f1_score(y_test2,y_pred_gaus),recall_score(y_test2,y_pred_gaus)],\n",
    "        'Linear':[accuracy_score(y_test2,y_pred_linear),f1_score(y_test2,y_pred_linear),recall_score(y_test2,y_pred_linear)],\n",
    "        'Poly':[accuracy_score(y_test2,y_pred_poly),f1_score(y_test2,y_pred_poly),recall_score(y_test2,y_pred_poly)]}\n",
    "\n",
    "\n",
    "pd.DataFrame(data=data,columns=['RBF','Linear','Poly'],index=['Accuracy','F1','Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie jądra uzyskły bardzo zbliżone i nie zbyt wysokie wyniki jak wspominałem wcześniej może to wynikać z trudności zbioru. SVM uzyskuje też duży bład treningowy zbliżony do testowego co prawdopodobnie oznacza ,że jest to model zbyt prosty dla wybranego zbioru. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
