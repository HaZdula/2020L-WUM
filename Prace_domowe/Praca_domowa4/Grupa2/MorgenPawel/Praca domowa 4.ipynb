{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca domowa 4\n",
    "## Wstęp do uczenia maszynowego\n",
    "### Paweł Morgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pierwszy zbiór - apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m2.price</th>\n",
       "      <th>construction.year</th>\n",
       "      <th>surface</th>\n",
       "      <th>floor</th>\n",
       "      <th>no.rooms</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5897</td>\n",
       "      <td>1953</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Srodmiescie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1818</td>\n",
       "      <td>1992</td>\n",
       "      <td>143</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Bielany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3643</td>\n",
       "      <td>1937</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Praga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3517</td>\n",
       "      <td>1995</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Ochota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3013</td>\n",
       "      <td>1992</td>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Mokotow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m2.price  construction.year  surface  floor  no.rooms     district\n",
       "0      5897               1953       25      3         1  Srodmiescie\n",
       "1      1818               1992      143      9         5      Bielany\n",
       "2      3643               1937       56      1         2        Praga\n",
       "3      3517               1995       93      7         3       Ochota\n",
       "4      3013               1992      144      6         5      Mokotow"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apartments = pd.read_csv('apartments.csv')\n",
    "apartments_test = pd.read_csv('apartments_test.csv')\n",
    "apartments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drugi zbiór - drug consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiór [drug consumption](https://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29) zawiera informacje odnośnie profilu osobowości respondentów (wyniki z testu pięciu wymiarów osobowości), podstawowe informacje (wiek, płeć, rasa itd) oraz dane na temat spożycia narkotyków (zmienne celu). Zmienne informatywne (nie celu) zostały skwantyfikowane i mogą być traktowane jak zmienne numeryczne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>Ascore</th>\n",
       "      <th>...</th>\n",
       "      <th>Ecstasy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legalh</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>Semer</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>...</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Age   Gender  Education  Country  Ethnicity   Nscore   Escore  \\\n",
       "0   1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1   2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2   3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3   4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4   5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "\n",
       "    Oscore   Ascore  ...  Ecstasy  Heroin  Ketamine Legalh  LSD Meth  \\\n",
       "0 -0.58331 -0.91699  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n",
       "1  1.43533  0.76096  ...      CL4     CL0       CL2    CL0  CL2  CL3   \n",
       "2 -0.84732 -1.62090  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n",
       "3 -0.01928  0.59042  ...      CL0     CL0       CL2    CL0  CL0  CL0   \n",
       "4 -0.45174 -0.30172  ...      CL1     CL0       CL0    CL1  CL0  CL0   \n",
       "\n",
       "  Mushrooms Nicotine Semer  VSA  \n",
       "0       CL0      CL2   CL0  CL0  \n",
       "1       CL0      CL4   CL0  CL0  \n",
       "2       CL1      CL0   CL0  CL0  \n",
       "3       CL0      CL2   CL0  CL0  \n",
       "4       CL2      CL2   CL0  CL0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs = pd.read_table('drug_consumption.data', \n",
    "                      sep = ',',\n",
    "                     header = None,\n",
    "                     names = ['ID', 'Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS', 'Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'Semer', 'VSA'])\n",
    "drugs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inżynieria cech\n",
    "Zmienne kategoryczne dotyczące spożycia należy rozumieć w następujący sposób:\n",
    "\n",
    " * CL0 - nigdy nie używano\n",
    " * CL1 - używano ponad 10 lat temu\n",
    " * CL2 - używano w ciągu ostatnich 10 lat\n",
    " * CL3 - używano w ciągu ostatniego roku\n",
    " * CL4 - używano w ciągu ostatniego miesiąca\n",
    " * CL5 - używano w ciągu ostatniego tygodnia\n",
    " * CL6 - używano w ciągu ostatniego dnia\n",
    "\n",
    "Autorzy zawarli informacje o każdym typie używek w osobnych kolumnach. W tej pracy domowej skupię się na narkotykach *per se* (a więc nie interesują nas dane nt. spożycia alkoholu, kofeiny czy czekolady). W tym celu powstanie zbiorcza zmienna Drugs, zbierająca dane nt każdego rodzaju narkotyków.\n",
    "\n",
    "Autorzy pytali również o spożywanie fikcyjnego narkotyku *Semeron*. Respondentów twierdzących, że kiedykolwiek spożywali ten narkotyk, wykluczymy z puli jako niewiarygodnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuwamy kłamców\n",
    "drugs = drugs.loc[drugs.loc[:,'Semer'] == 'CL0'].reset_index()\n",
    "\n",
    "# Tworzymy zbiorczą kolumnę\n",
    "def decode_drugs(col):\n",
    "    col = col.str.replace('CL', '')\n",
    "    return pd.to_numeric(col)\n",
    "not_drugs = ['Alcohol','Amyl','Benzos', 'Caff', 'Cannabis', 'Choc', 'Nicotine', 'VSA']\n",
    "vec = drugs.loc[:,'Alcohol':'VSA'].drop(not_drugs, axis = 1).apply(decode_drugs).apply(axis = 1, func = np.max)\n",
    "\n",
    "# Pozbywamy się danych nie-numerycznych i dodajemy zbiorczą kolumnę. \n",
    "# Osoby, które od co najmniej 10 lat NIE zażywały narkotyków zaliczamy do grupy '0', a resztę - '1'.\n",
    "conv = np.array([0,0,1,1,1,1])\n",
    "drugs = drugs.loc[:,\"Age\":\"SS\"].assign(Drugs = pd.Series(conv[vec - 1]).astype('category'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC for scaled: 0.2258825697442548\n",
      "MCC for unscaled: 0.14112030799723416\n",
      "Accuracy for scaled: 0.30177777777777776\n",
      "Accuracy for unscaled: 0.21955555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, classification_report\n",
    "\n",
    "# Podział na zbiór testowy i treningowy\n",
    "\n",
    "apts_x_train = apartments.drop('district', axis = 1)\n",
    "apts_y_train = apartments.loc[:,'district']\n",
    "apts_x_test = apartments_test.drop('district', axis = 1)\n",
    "apts_y_test = apartments_test.loc[:,'district']\n",
    "\n",
    "drugs_x_train, drugs_x_test, drugs_y_train, drugs_y_test = train_test_split(drugs.drop('Drugs', axis = 1),\n",
    "                                                                           drugs.loc[:,'Drugs'],\n",
    "                                                                           test_size = 0.3)\n",
    "# Nie ma potrzeby kodowania zmiennych\n",
    "# Skalujemy ?\n",
    "\n",
    "steps_scaled = [('scale', StandardScaler()),\n",
    "               ('SVM', SVC(kernel = 'rbf', class_weight = 'balanced'))]\n",
    "steps_raw = [('SVM', SVC(kernel = 'rbf', class_weight = 'balanced'))]\n",
    "\n",
    "pip_scaled = Pipeline(steps_scaled)\n",
    "pip_raw = Pipeline(steps_raw)\n",
    "\n",
    "pip_scaled.fit(apts_x_train, apts_y_train)\n",
    "pip_raw.fit(apts_x_train, apts_y_train)\n",
    "\n",
    "apts_pred_scaled = pip_scaled.predict(apts_x_test)\n",
    "apts_pred_raw = pip_raw.predict(apts_x_test)\n",
    "\n",
    "print(\"MCC for scaled: {}\".format(matthews_corrcoef(apts_y_test, apts_pred_scaled)))\n",
    "print(\"MCC for unscaled: {}\".format(matthews_corrcoef(apts_y_test, apts_pred_raw)))\n",
    "print(\"Accuracy for scaled: {}\".format(accuracy_score(apts_y_test, apts_pred_scaled)))\n",
    "print(\"Accuracy for unscaled: {}\".format(accuracy_score(apts_y_test, apts_pred_raw)))\n",
    "# print(classification_report(apts_y_test, apts_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC for scaled: 0.23663838960962408\n",
      "MCC for unscaled: 0.2655264573405789\n",
      "Accuracy for scaled: 0.6134751773049646\n",
      "Accuracy for unscaled: 0.6365248226950354\n"
     ]
    }
   ],
   "source": [
    "pip_scaled = Pipeline(steps_scaled)\n",
    "pip_raw = Pipeline(steps_raw)\n",
    "\n",
    "pip_scaled.fit(drugs_x_train, drugs_y_train)\n",
    "pip_raw.fit(drugs_x_train, drugs_y_train)\n",
    "\n",
    "drugs_pred_scaled = pip_scaled.predict(drugs_x_test)\n",
    "drugs_pred_raw = pip_raw.predict(drugs_x_test)\n",
    "\n",
    "print(\"MCC for scaled: {}\".format(matthews_corrcoef(drugs_y_test, drugs_pred_scaled)))\n",
    "print(\"MCC for unscaled: {}\".format(matthews_corrcoef(drugs_y_test, drugs_pred_raw)))\n",
    "print(\"Accuracy for scaled: {}\".format(accuracy_score(drugs_y_test, drugs_pred_scaled)))\n",
    "print(\"Accuracy for unscaled: {}\".format(accuracy_score(drugs_y_test, drugs_pred_raw)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla zbioru `apartments` obsewrujemy spory spadek w skuteczności. Zbiór `drugs` już jest zbalansowany, zatem brak różnic w skuteczności modelu nas nie zaskakuje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optymalizacja hiperparametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters_rbf = {'SVM__C': np.power(10,np.linspace(-2, 2, 10)),\n",
    "                  'SVM__gamma': np.power(10,np.linspace(-2, 0, 10))}\n",
    "parameters_poly = {'SVM__C': np.power(10,np.linspace(-2, 2, 5)),\n",
    "                  'SVM__gamma': np.power(10,np.linspace(-2, 0, 5)),\n",
    "                  'SVM__degree' : [2,3,4]}\n",
    "parameters_lin = {'SVM__C': np.power(10,np.linspace(-2, 2, 100))}\n",
    "\n",
    "steps_rbf = [('scale', StandardScaler()),\n",
    "            ('SVM', SVC(kernel = 'rbf', class_weight = 'balanced', cache_size = 800))]\n",
    "steps_poly = [('scale', StandardScaler()),\n",
    "            ('SVM', SVC(kernel = 'poly', class_weight = 'balanced', cache_size = 800))]\n",
    "steps_lin = [('scale', StandardScaler()),\n",
    "            ('SVM', SVC(kernel = 'linear', class_weight = 'balanced', cache_size = 800))]\n",
    "\n",
    "pip_rbf = Pipeline(steps_rbf)\n",
    "pip_poly = Pipeline(steps_poly)\n",
    "pip_lin = Pipeline(steps_lin)\n",
    "\n",
    "cv_rbf = GridSearchCV(pip_rbf, parameters_rbf, n_jobs = -1, cv = 3)\n",
    "cv_poly = GridSearchCV(pip_poly, parameters_poly, n_jobs = -1, cv = 3)\n",
    "cv_lin = GridSearchCV(pip_lin, parameters_lin, n_jobs = -1, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting\n",
      "rbf fitted\n",
      "poly fitted\n",
      "linear fitted\n",
      "MCC with gaussian kernel: 0.22805194582334865\n",
      "MCC with polynomial kernel: 0.22868185880021788\n",
      "MCC with linear kernel: 0.2396963616362826\n"
     ]
    }
   ],
   "source": [
    "print('Starting fitting')\n",
    "cv_rbf.fit(apts_x_train, apts_y_train)\n",
    "print('rbf fitted')\n",
    "cv_poly.fit(apts_x_train, apts_y_train)\n",
    "print('poly fitted')\n",
    "cv_lin.fit(apts_x_train, apts_y_train)\n",
    "print('linear fitted')\n",
    "\n",
    "apts_pred_rbf = cv_rbf.predict(apts_x_test)\n",
    "apts_pred_poly = cv_poly.predict(apts_x_test)\n",
    "apts_pred_lin = cv_lin.predict(apts_x_test)\n",
    "\n",
    "print(\"MCC with gaussian kernel: {}\".format(matthews_corrcoef(apts_y_test, apts_pred_rbf)))\n",
    "print(\"MCC with polynomial kernel: {}\".format(matthews_corrcoef(apts_y_test, apts_pred_poly)))\n",
    "print(\"MCC with linear kernel: {}\".format(matthews_corrcoef(apts_y_test, apts_pred_lin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVM__C': 100.0, 'SVM__gamma': 0.0774263682681127}\n",
      "{'SVM__C': 1.0, 'SVM__degree': 3, 'SVM__gamma': 1.0}\n",
      "{'SVM__C': 0.5462277217684343}\n"
     ]
    }
   ],
   "source": [
    "print(cv_rbf.best_params_)\n",
    "print(cv_poly.best_params_)\n",
    "print(cv_lin.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fitting\n",
      "rbf fitted\n",
      "poly fitted\n",
      "linear fitted\n",
      "MCC with gaussian kernel: 0.07205760409319376\n",
      "MCC with polynomial kernel: 0.11315233231990394\n",
      "MCC with linear kernel: 0.3048142350121146\n"
     ]
    }
   ],
   "source": [
    "print('Starting fitting')\n",
    "cv_rbf.fit(drugs_x_train, drugs_y_train)\n",
    "print('rbf fitted')\n",
    "cv_poly.fit(drugs_x_train, drugs_y_train)\n",
    "print('poly fitted')\n",
    "cv_lin.fit(drugs_x_train, drugs_y_train)\n",
    "print('linear fitted')\n",
    "\n",
    "drugs_pred_rbf = cv_rbf.predict(drugs_x_test)\n",
    "drugs_pred_poly = cv_poly.predict(drugs_x_test)\n",
    "drugs_pred_lin = cv_lin.predict(drugs_x_test)\n",
    "\n",
    "print(\"MCC with gaussian kernel: {}\".format(matthews_corrcoef(drugs_y_test, drugs_pred_rbf)))\n",
    "print(\"MCC with polynomial kernel: {}\".format(matthews_corrcoef(drugs_y_test, drugs_pred_poly)))\n",
    "print(\"MCC with linear kernel: {}\".format(matthews_corrcoef(drugs_y_test, drugs_pred_lin)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "W obu przypadkach najlepsze okazało się użycie jądra liniowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for apartments:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Bemowo       0.17      0.36      0.23       896\n",
      "     Bielany       0.17      0.01      0.02       894\n",
      "     Mokotow       0.35      0.09      0.14       868\n",
      "      Ochota       0.36      0.49      0.42       909\n",
      "       Praga       0.19      0.26      0.22       971\n",
      " Srodmiescie       1.00      1.00      1.00       924\n",
      "       Ursus       0.18      0.20      0.19       920\n",
      "     Ursynow       0.15      0.01      0.02       864\n",
      "        Wola       0.16      0.19      0.17       892\n",
      "    Zoliborz       0.34      0.47      0.39       862\n",
      "\n",
      "    accuracy                           0.31      9000\n",
      "   macro avg       0.31      0.31      0.28      9000\n",
      "weighted avg       0.31      0.31      0.28      9000\n",
      "\n",
      "Report for drugs:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.84      0.45       107\n",
      "           1       0.94      0.55      0.69       457\n",
      "\n",
      "    accuracy                           0.60       564\n",
      "   macro avg       0.62      0.69      0.57       564\n",
      "weighted avg       0.82      0.60      0.64       564\n",
      "\n",
      "Confusion matrix for drugs:\n",
      "[[ 90  17]\n",
      " [207 250]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('Report for apartments:')\n",
    "print(classification_report(apts_y_test, apts_pred_lin))\n",
    "\n",
    "\n",
    "print('Report for drugs:')\n",
    "print(classification_report(drugs_y_test, drugs_pred_lin))\n",
    "print('Confusion matrix for drugs:')\n",
    "print(confusion_matrix(drugs_y_test, drugs_pred_lin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie zachwyca. Porównajmy z regresją logistyczną:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.71      0.42       107\n",
      "           1       0.90      0.61      0.72       457\n",
      "\n",
      "    accuracy                           0.63       564\n",
      "   macro avg       0.60      0.66      0.57       564\n",
      "weighted avg       0.79      0.63      0.67       564\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 76  31]\n",
      " [180 277]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(class_weight = 'balanced')\n",
    "logreg.fit(drugs_x_train, drugs_y_train)\n",
    "logreg_pred = logreg.predict(drugs_x_test)\n",
    "\n",
    "print(classification_report(drugs_y_test, logreg_pred))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(drugs_y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki są porównywalne. Oba modele mają porównywalny f1-score. `SVM` wykrył więcej *true positives*, ale mniej *true negatives*. \n",
    "Stąd wniosek, że dane najzwyczajniej w świecie stanowią wyzwanie dla modeli ML."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
