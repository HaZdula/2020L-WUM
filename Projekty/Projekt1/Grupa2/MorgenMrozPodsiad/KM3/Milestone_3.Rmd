---
title: "Milestone_3"
author: "Paweł Morgen, Zuzanna Mróz, Aleksander Podsiad"
date: "21/04/2020"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    code_folding: show
    number_sections: true
---

# Wytrenowane modele

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source('load&preprocessing.R')
library(ranger)
library(gbm)
library(ada)
library(xgboost)
load('models/ada_tuned.rda')
load('models/gbm_tuned.rda')
load('models/ranger_tuned.rda')
load('models/xgb_tuned.rda')
```

Łącznie wytrenowano 5 modeli. Jeden już widzieliśmy (drzewo decyzyjne) w poprzednim kamieniu milowym. Teraz doszły:

* Las losowy - `ranger`
* Gradient boost - `gbm`
* ADA boost - `ada`
* XGboost - `xgboost`

W każdym z powyższych czterech hiperparametry były strojone metodą RandomSearch.

# Porównanie

```{r comp}
set.seed(123)
m <- sample(1:nrow(data_mod), 0.7*nrow(data2))
data_test1 <- data2[-m,]
task_test_1 <- makeClassifTask(data = data_test1, target = 'customer_type')
data_test2 <- data_mod[-m,]
task_test_2 <- makeClassifTask(data = data_test2, target = 'customer_type')
res <-
  list(
    performance(
      predict(ranger_tuned, task = task_test_1),
      measures = list(auc, acc,
                      mcc, ppv)
    )
    %>% as.list() %>% as.data.frame(),
    performance(
      predict(gbm_tuned, task = task_test_1),
      measures = list(auc, acc,
                      mcc, ppv)
    )
    %>% as.list() %>% as.data.frame(),
    performance(
      predict(model_ada_tuned, task = task_test_2),
      measures = list(auc, acc,
                      mcc, ppv)
    )
    %>% as.list() %>% as.data.frame(),
    performance(
      predict(model_xgb_tuned, task = task_test_2),
      measures = list(auc, acc,
                      mcc, ppv)
    )
    %>% as.list() %>% as.data.frame()
  )
knitr::kable(bind_rows(res) %>% mutate(Model = c('Random Forest',
                                                 'Gradient Boost',
                                                 'ADA Boost',
                                                 'XGBoost')))

```

Jak widzimy, przy wzięciu pod uwagę kilku różnych metryk, najlepszy okazał się zwykły las losowy - mimo zbliżonych wyników.

# Interpretacja modelu

```{r xai, cache=TRUE, message=FALSE, warning=FALSE}
library(DALEX)
ranger_tuned_raw <- getLearnerModel(ranger_tuned)
ranger_exp <- explain(ranger_tuned_raw,
                      data = data_test1[,-which(names(data_test1) == 'customer_type')],
                      y = data_test1$customer_type,
                      label = 'Random forest', 
                      verbose = FALSE)
ranger_fi <- variable_importance(ranger_exp, loss_function = loss_one_minus_auc)
ranger_pd_nums <- variable_effect(ranger_exp, variables = c('duration',
                                                            'credit_amount'))
ranger_pd_cat_1 <- variable_effect(ranger_exp, variables = 'checking_account_status')
ranger_pd_cat_2 <- variable_effect(ranger_exp, variables =                           'credit_history')
plot(ranger_fi)
plot(ranger_pd_cat_1) + ggplot2::coord_flip()
plot(ranger_pd_nums)
plot(ranger_pd_cat_2) + ggplot2::coord_flip()
```

# Podsumowanie

Po użyciu pakietu `DALEX` możemy w większym stopniu zinterpretować model `ranger` i wyjaśnić jego poszczególne komponenty.
Najważniejszymi zmiennymi przy określaniu typu klienta okazały się:

 * `checking_account_status` - stan rachunku bieżącego
 * `credit_amount` - wysokość kredytu
 * `credit_history` - podsumowanie historii kredytów
 * `savings` - oszczędności

Najczęstsze przewidywania modelu o tym, że klient jest ‘dobry’ miały miejsce, gdy zmienna
`checking_account_status` przyjmowała wartość `no_checking_account` i `>=200DM/salary assignments
for 1+ year`.
Przy zależnościach zmiennych `duration` oraz `credit_amount` możemy zauważyć, że im dłuższy jest czas
trwania kredytu tym częśiej klienci oceniani są jako ‘źli’. 
Wyskość kredytu nie powinna być zbyt niska, ani zbyt wysoka.
Jeśli z kolei popatrzymy na historię kredytów, to co ciekawe najniższą średnią predykcji mają klienci, którzy
mają wszystkie kredyty spłacone.
Oznacza to, że klienci którzy nadal spłacają kredyt albo nawet mają
opóźnienia w spłacaniu klasyfikowani są jako ‘dobrzy’ częściej niż ci ze spłaconymi kredytami. Jest to bardzo
ciekawe zjawisko bardzo sprzeczne z intuicją.